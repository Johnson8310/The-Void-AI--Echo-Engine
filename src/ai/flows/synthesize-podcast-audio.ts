
'use server';
/**
 * @fileOverview Generates the podcast audio file from the edited script using the selected AI voices.
 *
 * - synthesizePodcastAudio - A function that handles the podcast audio synthesis process.
 * - SynthesizePodcastAudioInput - The input type for the synthesizePodcastAudio function.
 * - SynthesizePodcastAudioOutput - The return type for the synthesizePodcastAudioOutput function.
 */

import {z} from 'zod';
import {ai} from '@/ai/genkit';
import { googleAI } from '@genkit-ai/googleai';
import wav from 'wav';

const SynthesizePodcastAudioInputSchema = z.object({
  script: z.string().describe('The edited script with speaker cues.'),
  voiceConfig: z
    .record(z.string(), z.object({voiceName: z.string()}))
    .describe(
      'A map of speaker names to their AI voice names. A special `__default` key can be used for a single voice.'
    ),
});

export type SynthesizePodcastAudioInput = z.infer<
  typeof SynthesizePodcastAudioInputSchema
>;

const SynthesizePodcastAudioOutputSchema = z.object({
  podcastAudioUri: z
    .string()
    .describe(
      'The data URI of the generated podcast audio file in WAV format.'
    ),
});

export type SynthesizePodcastAudioOutput = z.infer<
  typeof SynthesizePodcastAudioOutputSchema
>;

function toWav(
  pcmData: Buffer,
  channels = 1,
  rate = 24000,
  sampleWidth = 2
): Promise<string> {
  return new Promise((resolve, reject) => {
    const writer = new wav.Writer({
      channels,
      sampleRate: rate,
      bitDepth: sampleWidth * 8,
    });

    const bufs: Buffer[] = [];
    writer.on('error', reject);
    writer.on('data', (chunk) => {
      bufs.push(chunk);
    });
    writer.on('end', () => {
      resolve(Buffer.concat(bufs).toString('base64'));
    });

    writer.write(pcmData);
    writer.end();
  });
}

function formatMultiSpeakerScript(script: string, speakers: string[]): string {
    // Escape special regex characters in speaker names
    const escapedSpeakers = speakers.map(s => s.replace(/[-\/\\^$*+?.()|[\]{}]/g, '\\$&'));
    const speakerRegex = new RegExp(`^(${escapedSpeakers.join('|')}):\\s*(.+)`, 'i');
    
    const lines = script.split('\n');
    const formattedLines: string[] = [];

    for (const line of lines) {
        const match = line.match(speakerRegex);
        if (match) {
            const speaker = match[1].trim();
            const text = match[2].trim();
            // Ensure speaker is one of the provided speakers and text exists
            if(text && speakers.includes(speaker)) {
              formattedLines.push(`${speaker}: ${text}`);
            }
        }
    }
    return formattedLines.join('\n');
}

export async function synthesizePodcastAudio(
  input: SynthesizePodcastAudioInput
): Promise<SynthesizePodcastAudioOutput> {
  const {script, voiceConfig} = input;

  const isMultiSpeaker = !voiceConfig['__default'];
  
  let ttsPrompt = script;
  const config: any = {
    responseModalities: ['AUDIO'],
    speechConfig: {},
  };

  if (isMultiSpeaker) {
    const speakers = Object.keys(voiceConfig).filter(k => k !== '__default');
    ttsPrompt = formatMultiSpeakerScript(script, speakers);
    config.speechConfig.multiSpeakerVoiceConfig = {
      speakerVoiceConfigs: speakers.map(speaker => ({
        speaker: speaker,
        voiceConfig: {
          prebuiltVoiceConfig: { voiceName: voiceConfig[speaker].voiceName },
        },
      })),
    };
  } else {
    config.speechConfig.voiceConfig = {
      prebuiltVoiceConfig: { voiceName: voiceConfig['__default'].voiceName },
    };
  }

  if (!ttsPrompt.trim()) {
    throw new Error(
      "The script is empty or could not be parsed into valid speaker segments. Please ensure the script has text to speak."
    );
  }

  try {
    const { media } = await ai.generate({
        model: googleAI.model('gemini-2.5-flash-preview-tts'),
        config,
        prompt: ttsPrompt,
    });

    if (!media?.url) {
      throw new Error('No audio was generated by the model.');
    }

    const audioBuffer = Buffer.from(
      media.url.substring(media.url.indexOf(',') + 1),
      'base64'
    );
    
    const wavBase64 = await toWav(audioBuffer);
  
    return {podcastAudioUri: `data:audio/wav;base64,${wavBase64}`};

  } catch (error: any) {
    console.error('Error with Google AI TTS API:', error);
    // Provide a more specific error message if possible
    const detail = error.details || error.message || 'An unknown error occurred.';
    throw new Error(`Failed to synthesize audio with Google AI: ${detail}`);
  }
}
